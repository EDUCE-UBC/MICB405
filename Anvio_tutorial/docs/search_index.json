[["introduction.html", "Introduction 1 Introduction 1.1 Guide to the book 1.2 Brief introduction to omics methods 1.3 Some key aspects of metagenomics 1.4 Key points to be aware of and known pitfalls in metagenomics 1.5 Basic outline of a metagenomics pipeline", " Introduction Pranav_Sampara 05/11/2020 1 Introduction This book is a brief guide to illustrate a typical binning and manual refinement workflow on the Anvio platform. This book uses four binning tools - METABAT2, MAXBIN2, CONCOCT, and DASTool. CheckM is used for MAG quality assessment and GTDB-Tk is used for taxonomic classification. Finally, TreeSAPP is used for functional annotation. 1.1 Guide to the book An introduction to omics methods is provided with a commentary and focus on metagenomics. Typical workflow, key points, and usual pitfalls for metagenomic analysis is provided Later, an introduction to the exercise that is to be done on Anvio is provided. This part of the book contains the project brief, data collection, and description of the data provided to students is discussed Next, a brief introduction and installation guide to Anvio and binning tools is provided Finally, example scripts are provided to achieve the final goal of high quality bins, taxonomic classification, and functional annotation of interested taxa. Clearly, this book is an introduction to binning and refinement. To maximize the benefit of this tutorial, please read the supporting scientific literature wherever provided and beyond. 1.2 Brief introduction to omics methods 1.3 Some key aspects of metagenomics A few key aspects that make metagenomics a valuable tool are: Ecophysiology: Enables the study of who is capable of doing what. In other words, function and identity relationships in the community or ecosystem of interest can be probed. Read Spang et al. 2019 Ecology: Estimate community characteristics  richness, diversity indices. Additionally, specific community functions can be investigated. Read Louca et al. 2016 Evolution: Finally, an investigation into how populations evolve in their natural habitat is possible with metagenomics. Particularly, selective pressures, if any, can be identified. Of course, you may need time-series sequencing and biogeochemistry data associated with the ecosystem of interest. Read Sun et al. 2016 1.4 Key points to be aware of and known pitfalls in metagenomics 1.5 Basic outline of a metagenomics pipeline Although there can be many means to make sense of the information in metagenomic datasets, a typical workflow consists of the following steps after generating sequencing data: Quality control, or polishing, of the raw reads Assembly of the raw reads into contiguous sequences, or contigs, and scaffolds Generation of coverage information by mapping the assembled reads to the polished reads Using sequence composition and coverage information to group, or bin, similar contigs. These bins are referred to as metagenome-assembled genomes or MAGs Quality control of the MAGs to assess completion and contamination Taxonomic classification and functional annotation of MAGs to identify who is present and what their metabolic potential is Phylogenomic or phylogenetic study of genomes or genes of interest and pangenomic analysis of similar taxa can be also be done to study the community networks "],["metagenomics-workflow.html", "2 Metagenomics workflow", " 2 Metagenomics workflow Assembly (vs. co-assembly) Mapping Binning Quality control on the bins Taxonomic classification Functional annotation Any other downstream functions "],["background-information.html", "3 Background information 3.1 Project information 3.2 Data collection 3.3 Data availability 3.4 Goal of the exercise", " 3 Background information 3.1 Project information 3.2 Data collection 3.3 Data availability 3.4 Goal of the exercise The idea is to generate high quality metagenome assembled genomes (MAGs), identify the taxonomy, and the metabolic potential of the MAGs of interest. The following chapters provide more information on each of these steps "],["introduction-to-anvio.html", "4 Introduction to Anvio 4.1 What is Anvio 4.2 Anvio installation 4.3 Binning tools installation", " 4 Introduction to Anvio 4.1 What is Anvio Analysis and visualization platform for omics data, or Anvio is an open source platform for analyzing integrated multi-omics data developed by Eren et al. 2015. Anvio provides an excellent platform to visualize and analyze multi-omics data. We would use the platform to bin metagenome assembled genomes (MAGs) and manually refine the MAGs. Please visit Anvio webpage to learn more about Anvio and Anvio usage We would then summarize, or output, the MAGs and perform quality control by estimating the completion and redundancy of the MAGs using CheckM developed by Parks et al. 2015. Later, we would classify the MAGs using GTDB-Tk developed by Chaumeil et al. 2020 4.2 Anvio installation The following instructions provide an overview of commands that should work for most systems. For detailed instructions please see Anvio installation resources. Step 1: Please have a working install of miniconda on your terminal. Conda installation of Anvio is hassle-free and quick. Make sure the installation is updated by running conda update conda Step 2: For Mac OSX users # first get a copy of the following file (if you get a &quot;command not found&quot; # error for wget, you can either install it first, or manually download the # file from that URL: wget http://merenlab.org/files/anvio-conda-environments/anvio-environment-6.2.yml # just to make sure there is not a v6.2 environment already: conda env remove --name anvio-6.2 # create a new v6.2 environment using the file you just downloaded: conda env create -f anvio-environment-6.2.yml # activate that environment conda activate anvio-6.2 Linux / Windows users: conda create -y --name anvio-6.2 python=3.6 conda activate anvio-6.2 conda install -y -c conda-forge -c bioconda anvio==6.2 Step 3: Confirm installation anvi-self-test --suite mini If all is well, your browser should open and load the test run results 4.3 Binning tools installation While we are installing Anvio, we might as well install binning tools that we would use along with Anvio. Here we install - METABAT2 developed by Kang et al. 2019 MAXBIN2 developed by Wu et al. 2016 CONCOCT developed by Alneberg et al. 2014 DASTOOL developed by Sieber et al. 2018 # Metabat2 conda install metabat2 #Maxbin2 conda install maxbin2 #Concoct conda install -c bioconda concoct #DAS_Tool conda install -c bioconda das_tool To verify if these binning tools are accessible by Anvio, please run these commands: conda activate anvio-6.2 anvi-cluster-contigs --help You should get a help menu on how to use the binning tools in Anvio. If there is a binning tool that is not accessible, you should see [NOT FOUND] next to the binning tool name. If you do not see this tex next to the three binning tools you installed, you are good to proceed. CheckM and GTDB-Tk should be installed on your terminal "],["anvio-binning-exercise.html", "5 Anvio binning exercise 5.1 Automatic binning on Anvio using METABAT2, MAXBIN2, and CONCOCT 5.2 Assessing quality bins 5.3 Manual refinement 5.4 Iterative assessment and refinement", " 5 Anvio binning exercise You will be provided with contigs and merged profiles database to run binning and later manual refinement on the bins. Please see this tutorial on assembly-based metagenomics and metagenomic workflow tutorial on Anvio to understand how these files were obtained and an in-depth explanation on moving forward. The Anvio documentation also provides an excellent commentary on the nuances of each step. 5.1 Automatic binning on Anvio using METABAT2, MAXBIN2, and CONCOCT The following commands provide a step by step approach to obtain bins and to load the results on the visualization platform of Anvio on your browser for manual refinement. #Create variables for profile and contig databases for easy access to files profile_db = ~/path_to_profile_db contig_db = ~/path_to_contig_db #Make output directory Mkdir ~/path_to_output_directory #Create variable for output directory bin_out=~/path_to_output_directory #Operational parameters threads=32 #Change to suitable amount of threads #Clustering with metabat2 anvi-cluster-contigs -p $profile_db -c $contig_db -C metabat --driver metabat2 -T $threads --just-do-it #Clustering with concoct anvi-cluster-contigs -p $profile_db -c $contig_db -C concoct --driver concoct -T $threads --just-do-it #Clustering with maxbin2 anvi-cluster-contigs -p $profile_db -c $contig_db -C maxbin --driver maxbin2 -T $threads --just-do-it #Consensus binning with DASTOOL anvi-cluster-contigs -p $profile_db -c $contig_db --driver dastool -S metabat,concoct,maxbin -C dastool --just-do-it -T $threads #Obtain bins as fasta files anvi-summarize -p $profile_db -c $contig_db -C dastool -o $bin_out/dastool_out #Copy all bin fasta files for downstream processing such as quality estimation, taxonomic classification, and functional annotation #Make directory for fasta files for easy access mkdir $bin_out/fasta_files cp $bin_out/dastool_out/*/*fasta $bin_out/fasta_files 5.1.1 Note to EDUCE-TAs In case we want the students to practice manual refinement alone, we can provide them with contaminated bins using Concoct. The following commands creates a fixed number of bins (ideally lower than the actual genomes expected) using Concoct profile_db = ~/path_to_profile_db contig_db = ~/path_to_contig_db #Make output directory Mkdir ~/path_to_output_directory #Operational parameters threads=32 #Change to suitable amount of threads bins=N #Change N to half of the number of bins expected to deliberately contaminate bins and later manually refine them #Clustering with concoct anvi-cluster-contigs -p $profile_db -c $contig_db -C concoct --driver concoct -T $threads --just-do-it --clusters $bins 5.2 Assessing quality bins Check completion and redundancy of MAGs using CheckM. Change paths and operational parameters as required for your system. For a more detailed understanding of how to use CheckM please visit CheckM wiki #Create checkM output directory mkdir ~/path_to_checkm_output_dir #Create variable for output directory checkm_out=~/path_to_checkm_output_dir #Establish bins fasta files directory in_fasta=~/path_to_output_fasta_files #Operational parameters  change as required on your system threads=48 pplacer_threads=24 #Run CheckM checkm lineage_wf -t $threads --pplacer_threads $pplacer_threads \\ -f $checkm_out/checkm_out.tsv --tab_table \\ -x fasta $in_fasta $checkm_out/checkm_lineage_wf #checkm_out.tsv is a tab separated file that provides quality estimates on the set of bins 5.2.1 Note the MAG quality Open the tab separated file, checkm_out.tsv in a spreadsheet viewer and study the completion and contamination column. We are looking for high/medium quality MAGs For a detailed commentary on high-quality MAGs, please refer Bowers et al. 2017 For this exercise, we aim to have bins with less than 10 % contamination and more than 50 % completion. We would now use the anvi-refine feature to manually refine the bins which have more than 10 % contamination. Please make a note of all the bins which are more than 50 % complete and have more than 10 % contamination. 5.3 Manual refinement Manual refinement on Anvio is described in great detail here 5.4 Iterative assessment and refinement After manual refinement of the bins on Anvio, iteratively run quality assessment and manual refinement of high contamination bins until you have a list of bins which are more than 90 % complete and less than 10 % contaminated. "],["processing-mags.html", "6 Processing MAGs 6.1 Taxonomic classification using GTDB-Tk", " 6 Processing MAGs Taxonomic classification can be done with GTDB-Tk. GTDB-Tk is a toolkit for using the Genome Taxonomy Database (GTDB) to classify taxonomy of the MAGs. Please read Parks et al. 2018 to learn more about GTDB and Chaumeil et al. 2020 for details on the GTDB-Tk tool. For an in-depth commentary on how to utilize GTDB-Tk please visit https://ecogenomics.github.io/GTDBTk/ After taxonomic classification, functional annotation can be done using TreeSAPP You will be implementing a pipeline called Tree-based Sensitive and Accurate Protein Profiler (TreeSAPP) for automated reconstruction of the nitrogen cycle along defined redox gradients in Saanich Inlet using the Google Cloud Platform. TreeSAPP takes either metagenomic or metatranscriptomic reads and aligns them to previously binned sequence data with each bin representing a putative microbial taxon. TreeSAPP determines three things: A. What taxa are in our metagenomic and metatranscriptomic data represented? B. Which marker genes do these taxa contain (metagenomic data) or actually express (metatranscriptomic data)? C. At what levels are those genes represented (metagenomic data) or expressed by the taxon? Please see the TreeSAPP wiki for more information on treesapp assign, the subcommand you will use. You will be provided with a script template for both the shell and R portion of your analysis (treesapp_analysis.sh and treesapp_analysis.R) that will guide you as you develop your code. 6.1 Taxonomic classification using GTDB-Tk The following commands will generate taxonomic classification of archaeal and bacterial MAGs #Create GTDB-Tk output directory mkdir ~/path_to_gtdbtk_output_dir #Create variable for output directory gtdbtk_out=~/path_to_gtdb_output_dir #Establish bins fasta files directory in_fasta=~/path_to_output_fasta_files #Export GTDB-Tk data path export GTDBTK_DATA_PATH=~/path_to_GTDB_data #Operational parameters  change as required on your system threads=48 pplacer_threads=24 #Run GTDB-Tk gtdbtk classify_wf -x fa --genome_dir $in_fasta \\ --out_dir $gtdbtk_out \\ --cpus $threads \\ --pplacer_cpus $pplacer_threads You would obtain two soft links in the gtdbtk output directory, each for bacteria and archaea taxonomic classification. Please follow the soft link to locate the actual files for taxonomic classification, and download to your system. "],["references.html", "7 References", " 7 References Eren, A. M. et al. Anvio: an advanced analysis and visualization platform for omics data. PeerJ 3, e1319 (2015). Kang, D. D. et al. MetaBAT 2: an adaptive binning algorithm for robust and efficient genome reconstruction from metagenome assemblies. PeerJ 7, e7359 (2019). Wu, Y.-W., Simmons, B. A. &amp; Singer, S. W. MaxBin 2.0: an automated binning algorithm to recover genomes from multiple metagenomic datasets. Bioinformatics 32, 605607 (2016). Parks, D. H. et al. A standardized bacterial taxonomy based on genome phylogeny substantially revises the tree of life. Nat Biotechnol 36, 9961004 (2018). Sun, C. L., Thomas, B. C., Barrangou, R. &amp; Banfield, J. F. Metagenomic reconstructions of bacterial CRISPR loci constrain population histories. The ISME Journal 10, 858870 (2016). Louca, S. et al. Integrating biogeochemistry with multiomic sequence information in a model oxygen minimum zone. PNAS 113, E5925E5933 (2016). Spang, A. et al. Proposal of the reverse flow model for the origin of the eukaryotic cell based on comparative analyses of Asgard archaeal metabolism. Nature Microbiology 4, 11381148 (2019). "]]
