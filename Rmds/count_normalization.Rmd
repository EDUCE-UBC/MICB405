# DESeq2: count normalization

This tutorial will use many tools found in the tidyverse package to reproduce how DESeq2 calculates the size factors to normalize the count data.

```{r include = FALSE}
counts <- read_csv(here("data", "pasilla_gene_counts.csv"))
```

## Slides

```{r echo=FALSE}
xaringanExtra::embed_xaringan(url = "slides/lectures/count_normalization.html",
                              ratio = "4:3")
```

You can download the slides for this tutorial below.

```{r echo = FALSE}
downloadthis::download_file(
  path         = here("slides", "lectures", "count_normalization.html"),
  output_name  = "7_2_deseq2_count_normalization",
  button_label = "Download slides"
)
```

## Learning outcomes

By the end of this tutorial, you should be able to:

- Define the challenges of differential analysis.
- Apply different count normalization strategies.
- Reproduce count normalization of DESeq2 in R using tidyverse

::: rmdtip
You should have both [R and RStudio] installed. Please open RStudio and work with the examples by editing your `` `r params$project`.R`` script.
:::

## Setup

## R packages

We will work with the tidyverse package so make sure that it is loaded.

```{r eval = FALSE}
library(tidyverse)
```

## Data

The RNAseq data were collected from *Drosophila melanogaster* in which the splicing regulator Pasilla was depleted by RNAi (`treated`) or not (`untreated`) [@brooks2011]. Download the data set `pasilla_gene_counts.csv` below and place it in your `r params$project` directory.

```{r echo = FALSE}
downloadthis::download_file(
  path         = here("data", "pasilla_gene_counts.csv"),
  button_label = "Download Pasilla data set"
)
```

## Working with data frames

### Loading tabular data from a file

Data frames can be loaded into R using many different functions. In the tidyverse, they are called `read_*()`. For example, let's inspect `Spasilla_gene_counts.cs` which contains a table using Notepad (Windows) or TextEdit (macOS).

```{r echo = FALSE, comment = NA}
cat(paste(read_lines(here("data", "pasilla_gene_counts.csv"),
                     n_max = 4),
          collapse = "\n"),
    fill = TRUE)
```

You will notice that the first row is different from all the others, and it actually contains column names for our data. Each row after the first one makes up a row in the table. You will also notice that commas separate values in each row. The first element in each row (i.e. before the first comma) makes up the value in the first column, each second element the value in the second column, and so on. Such a file is described as having comma-separated values. For that reason, files with that format often have the extension `.csv`.

We can load `pasilla_gene_counts.csv` into R with `read_csv` for a comma-separated file and specify the arguments that describe our data as follows:

-   `file`: the name of the file you want to load as a character data type, i.e. wrapped in quotes.
-   `col_names`: can take either the value `TRUE` or `FALSE` and tells R if the first row contains column names.

```{r eval = FALSE}
read_csv(file = "pasilla_gene_counts.csv", col_names = TRUE)
```

The data are printed to the console in R.

### Save data in the environment

Since we want to do more with our data after reading it in, we need to save it as a variable in R with the `<-` operator. You can choose to name the object whatever you like, though this module assumes the names used below.

```{r eval = FALSE}
counts <- read_csv(file = "pasilla_gene_counts.csv", col_names = TRUE)
```

### Data exploration

Let's explore the data that we've imported into R by clicking on the triangle of the `counts` in the Environment tab in the top-right pane. You can see each column and its data type in a long list.

```{r echo = FALSE}
str(counts, give.attr = FALSE)
```

If we directly click on `counts` in our Environment tab on the top-right pane, we can view the table. Row and column names are in grey boxes, and data is in white boxes.

Using different functions, we can look at the dimensions of our data, number of rows, and number of columns:

```{r}
# Number of rows followed by number of columns
dim(counts)

# Number of rows
nrow(counts)

# Number of columns
ncol(counts)
```

We can list the column names using `colnames()`:

```{r}
colnames(counts)
```

We can call specific columns using the `$` notation, which is useful for calling an entire column, regardless of its length. For example, calling the `untreated1` column:

```{r}
head(counts$untreated1)
```

## Data wrangling with dplyr

A popular package for data wrangling is *dplyr* in the tidyverse. This package is so good at what it does and integrates so well with other popular tools like *ggplot2* that it has rapidly become the de-facto standard.

dplyr code is very readable because all operations are based on using dplyr functions or *verbs* (`mutate()`, `filter()`, ...). Each verb works similarly:

- Input data frame in the first argument.
- Other arguments can refer to variables as if they were local objects (i.e. you do not need to use quotes around a `"<variable>"` name and can just directly refer to it with `<variable>`).
- Output is another data frame.

### Creating of modifying variables with `mutate()`

Use `mutate()` to apply a transformation to some variable and assign it to a new variable. As the first step for determining the size factor for each sample, DESeq2 calculates the natural logarithm of each gene count.

```{r}
counts_single_log_column <- mutate(counts, log_untreated1 = log(untreated1))
```

If we want to determine the logarithm for each variable, then the code becomes quickly tedious and repetitive.

```{r}
counts_two_log_column <- mutate(counts,
                                log_untreated1 = log(untreated1),
                                log_untreated2 = log(untreated2))
```

Instead, we can use `across()` to apply the same function to each variable and overwrite it. We can select a range of variables with `<first_variable>:<last_variable>`.

```{r}
log_counts <- mutate(counts, across(treated1:untreated4, log))
```

Alternatively, we can define what variables the function NOT to apply to with `!`. In our example, we want to skip `gene_id`.

```{r}
log_counts <- mutate(counts, across(!gene_id, log))
```

### Summarizing across variables with `rowwise()` and `c_across()`

We can group our data with `rowwise()` and then use `c_across()`,to calculate the mean across multiple columns (step 2 of DESeq2 normalization). The mean of the log values is not as sensitive to outliers compared to the means of the count values themselves.

```{r}
log_counts_grouped <- rowwise(log_counts)
geometric_means <- mutate(log_counts_grouped,
                          mean = mean(c_across(treated1:untreated4)))
```

### Piping with `%>%`

Because of the basic dplyr verb syntax, these functions lend themselves to piping, i.e. taking the output of one function and passing it in as a (by default the first) argument of the following function.

```{r}
geometric_means <- log_counts %>% 
  rowwise() %>% 
  mutate(gm = mean(c_across(treated1:untreated4)))
```

### Remove groupings with `ungroup()`

Because we are finished with the row-wise operation, we should remove the grouping with `ungroup()`.

```{r}
geometric_means <- log_counts %>% 
  rowwise() %>% 
  mutate(gm = mean(c_across(treated1:untreated4))) %>% 
  ungroup()
```

### `filter()`

Conditional statements and logical operators are essential when working with data in R. You can use `filter()` to select specific rows based on a logical condition of a variable. For quick reference, here are the most commonly used statements and operators.

R code     | meaning
---------- | ---------------
`==`       | equals
`< or >`   | less/greater than
`<= or >= `| less/greater than or equal to
`%in%`     | in
`is.na()`  | is missing (NA)
`!`        | not (as in not equal to `!=`)
`&`        | and
`|`        | or

As step 3 of DESeq2 count normalization, all rows that contain an infinite value for their geometric mean are removed. `is.infinite()` would return rows where the variable is infinite. `!is.infinite()` returns rows where it is not.

```{r}
geometric_means <- log_counts %>% 
  rowwise() %>% 
  mutate(gm = mean(c_across(treated1:untreated4))) %>% 
  ungroup() %>% 
  filter(!is.infinite(gm))
```

In step 4 of DESeq2 of count normalization, the geometric mean is subtracted of each $log(count) - log(gm) = log\left(\frac{{counts}}{{gm}}\right)$, i.e. it looks at the ratio of the sample to the mean.

```{r}
ratio <- geometric_means %>% 
  mutate(across(treated1:untreated4, ~ . - gm))
```

### Column-wise operation with `summarise()`

Now that we know the ratio of sample to mean, we select the `median()` across all remaining genes for each sample. To calculate a summary statistic for a column, we use `summarise()`. Finally, we take the inverse logarithm to receive the size factor for each sample.

```{r}
size_factors <- ratio %>% 
  summarise(across(treated1:untreated4, ~ exp(median(.))))
```

## Additional resources

### Count normalization

- [Introduction to DGE by the Harvard Chan Bioinformatics Core](https://hbctraining.github.io/DGE_workshop_salmon_online/lessons/02_DGE_count_normalization.html)
- [StatQuest: DESeq2 part 1: Library Normalization](https://statquest.org/statquest-deseq2-part-1-library-normalization/)

### dplyr and tidyr

- [R cheatsheets](https://www.rstudio.com/resources/cheatsheets/) also available in RStudio under Help > Cheatsheets
- [Introduction to dplyr](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html)
- [dplyr tutorial](https://rpubs.com/justmarkham/dplyr-tutorial)
- [dplyr video tutorial](https://www.r-bloggers.com/hands-on-dplyr-tutorial-for-faster-data-manipulation-in-r/)
- [More functions in dplyr and tidyr](https://rpubs.com/bradleyboehmke/data_wrangling)
