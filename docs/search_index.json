[["index.html", "Anvi’o binning and refinement tutorial 1 Introduction 1.1 Guide to the book 1.2 Brief introduction to ’omics methods 1.3 Some key aspects of metagenomics 1.4 Key points to be aware of and known pitfalls in metagenomics 1.5 Basic outline of a metagenomics pipeline", " Anvi’o binning and refinement tutorial Pranav_Sampara 05/11/2020 1 Introduction This book is a brief guide to illustrate a typical binning and manual refinement workflow on the Anvio platform. This book uses four binning tools - METABAT2, MAXBIN2, CONCOCT, and DASTool. CheckM is used for MAG quality assessment and GTDB-Tk is used for taxonomic classification. Finally, TreeSAPP is used for functional annotation. 1.1 Guide to the book An introduction to ’omics methods is provided with a commentary and focus on metagenomics. Typical workflow, key points, and usual pitfalls for metagenomic analysis is provided Later, an introduction to the exercise that is to be done on Anvio is provided. This part of the book contains the project brief, data collection, and description of the data provided to students is discussed Next, a brief introduction and installation guide to Anvio and binning tools is provided Finally, example scripts are provided to achieve the final goal of high quality bins, taxonomic classification, and functional annotation of interested taxa. Clearly, this book is an introduction to binning and refinement. To maximize the benefit of this tutorial, please read the supporting scientific literature wherever provided and beyond. 1.2 Brief introduction to ’omics methods 1.3 Some key aspects of metagenomics A few key aspects that make metagenomics a valuable tool are: Ecophysiology: Enables the study of who is capable of doing what. In other words, function and identity relationships in the community or ecosystem of interest can be probed. Read Spang et al. 2019 Ecology: Estimate community characteristics – richness, diversity indices. Additionally, specific community functions can be investigated. Read Louca et al. 2016 Evolution: Finally, an investigation into how populations evolve in their natural habitat is possible with metagenomics. Particularly, selective pressures, if any, can be identified. Of course, you may need time-series sequencing and biogeochemistry data associated with the ecosystem of interest. Read Sun et al. 2016 1.4 Key points to be aware of and known pitfalls in metagenomics 1.5 Basic outline of a metagenomics pipeline Although there can be many means to make sense of the information in metagenomic datasets, a typical workflow consists of the following steps after generating sequencing data: Quality control, or polishing, of the raw reads Assembly of the raw reads into contiguous sequences, or contigs, and scaffolds Generation of coverage information by mapping the assembled reads to the polished reads Using sequence composition and coverage information to group, or bin, similar contigs. These bins are referred to as metagenome-assembled genomes or MAGs Quality control of the MAGs to assess completion and contamination Taxonomic classification and functional annotation of MAGs to identify who is present and what their metabolic potential is Phylogenomic or phylogenetic study of genomes or genes of interest and pangenomic analysis of similar taxa can be also be done to study the community networks "],["instructions.html", "2 Instructions 2.1 Goal of the exercise 2.2 Project ideas 2.3 Timeline 2.4 Reports 2.5 Assessment 2.6 UJEMI submission", " 2 Instructions 2.1 Goal of the exercise The goal is to generate high quality metagenome assembled genomes (MAGs), identify the taxonomy, and the metabolic potential of the MAGs of interest. You will be working with metagenomic data from Cruise #. You will be provided with prerequisite information, such as a merged profile database and contigs database, that you would use to bin MAGs and later classify the taxonomy. You would be working on an ’omics analysis and visualization platform, Anvi’o. For binning, you would use Metabat2, Maxbin2, Concoct, and DASTool. For taxonomic classification you would use CheckM and finally to check genome completeness and redundancy you would use CheckM. 2.2 Project ideas Determine what fractions of contigs map to MAGs vs contigs not in MAGs, as a way to evaluate the total amount of information available to evaluate Evaluate nitrogen cycling genes within MAGs using Prokka and TreeSAPP annotations -Compare taxonomic assignment TreeSAPP identified genes to GTDB-Tk assigned taxonomies of MAGs, generated using Anvi’o. Can you identify known groups based on published work -Evaluate changes in nitrogen cycling gene taxonomy and abundance at different depths in the Saanich inlet water column 2.3 Timeline The following provides an outline as well as some specific milestones within the project. 2.4 Reports Reports should be formatted as per the Instructions to Authors for the Journal of Bacteriology. Each group will complete one report with the following sections. 2.4.1 Abstract 200–250 words Note that an Importance section is not required. 2.4.2 Introduction 500–750 words Overview of the nitrogen cycle including its global impacts and microbial foundations. Introduce Saanich Inlet as a model ecosystem for studying microbial community responses to ocean deoxygenation e.g. seasonal cycles, relevant biogeochemistry, previous studies, etc. 2.4.3 Methods 300–500 words Briefly describe the data (sampling, sequencing, processing, etc.) Briefly describe your analysis methods including Anvi’o version and commands used Binning tools version and commands used CheckM and GTDB-Tk version and commands used. For GTDB-Tk, please mention the data release that was used R version and packages used Statistics (if applicable) Provide three shell scripts and one single R script (if any) (i.e “binning.sh”, “completion_redundancy.sh”, “taxonomic_classification.sh” and an R script “file_name.R”) as individual files (i.e. not as part of your manuscript) containing the complete code to generate your results. 2.4.4 Results 500–750 words Your analysis will focus on binning and manual refinement, generating high quality bins (assessed by CheckM), assigning taxonomy, and metabolic networks of interested taxa and gene modules (typically denitrification genes, but you can be creative) (which is given in your Canvas group name) and the following questions: You must include ≥ figures/panels with titles and full captions. These figures can be combined into multi-panel figures if desired. These figures would typically contain - The Anvi’o metagenome visualization and an example of a refined bin. - Completion and redundancy estimates with GTDB-Tk taxonomic classification at phylum and family levels - Plot depth of MAG coverage relative to the number of reads in the metagenome for each depth - Generate annotations for predicted ORFs on contigs and MAGs using Prokka, and - Compare recovery of nitrogen cycling genesbetween MAGs and assembled contigs between Prokka and TreeSAPP 2.4.5 Discussion 750–1000 words Frame your depth’s results within a broader discussion of Saanich Inlet and the other depths (Apr 6 discussion) Propose expected taxa and comment on coverage, and the reasoning behind these results Provide a discussion on metabolic networks of the interested taxa Future directions 2.4.6 References 10 or more formatted in the ASM style such as for the Journal of Bacteriology. If you are using a reference manager, this style can be downloaded for EndNote, Mendeley, or Zotero. Make sure to cite the data source papers! 2.5 Assessment Reports will account for 15% of the course marks distributed as follows. 2.5.1 Peer evaluation (5%) Total: 40 pts Peer assessment will occur through CATME wherein everyone will assess themselves and their group members. Marks will be scaled to your evaluation score with 90%+ (or 0.9+ out of 1 within CATME) counting as full marks. Individuals who do not adequately contribute to their group will forfeit the 5% contributions mark and may be asked to complete the project on their own. Peer assessment includes: Contributing to the team’s work Interacting with teammates Expecting quality Having related knowledge, skills, and abilities Individuals score themselves and all team members on a scale of 1 (unsatisfactory) – 3 (satisfactory) – 5 (excellent) in these categories. Scores are then averaged and scaled within team such that 1 corresponds to all team members contributing equally to all categories of assessment: 1+ = Mostly 5s 0.95 = Mostly 4s 0.8 = Mostly 3s 0.65 = Mostly 2s 0.5 = Mostly 1s Marks will be scaled to your CATME score based on the following: 0.9 - 1+ = 100% = 40 0.8 - 0.89 = 90% = 36 0.7 - 0.79 = 80% = 32 0.6 - 0.69 = 70% = 28 &lt;0.6 = Assessed on a case-by-case basis Unwarranted blanketed low scoring of your team or high scoring of yourself will result in the removal of your scores from the average so that they do not unfairly impact you or your team members. If issues occur within your group, please do not hesitate to contact Dr. Hallam (shallam@mail.ubc.ca), or Dr. Koenig (stephan.koenig@ubc.ca) at any point. 2.5.2 Report (10%) Total: 80 pts Each group will submit an electronic copy of their group’s final report (due April 24). Reports will be assessed on: Completion of relevant analyses toward answering biological questions Logic and completeness of conclusions made from these analyses Writing clarity, grammar, and style Figure clarity, effectiveness, and relevance Poor (0-1 pts) Below average (2-4 pts) Good (5-7 pts) Excellent (8-10 pts) Abstract Not provided Summarizes only part of the report or contains numerous inaccuracies Summarizes most of the report including relevant results; Some inaccuracies or missing pieces Accurately summarizes the report including background, relevant results, and conclusions; Few to no inaccuracies Introduction Background information not provided or provided but not relevant to the research question(s); Hypotheses / questions are not stated nor supported by relevant sources Background is relevant but not sufficient to frame the research question(s); Hypotheses / questions are unclear and/or unsupported Background is relevant but does not fully frame the research question(s); Hypotheses / questions are unclear or unsupported Background is relevant and fully frames the research question(s); Hypotheses / questions are clearly stated and supported by scientific sources Methods Incomplete and missing numerous methods used; Unclear or confusing Missing several methods used; Numerous errors or unclear statements Missing one or more methods used; Results could not be replicated due to issues with clarity or accuracy Sufficient to allow replication of the results including sampling, sequencing, processing, and analysis; Succinct and not overly wordy Code (R and TreeSAPP) Code missing significant portions or is not provided Code is incomplete or erroneous such that results cannot be replicated; No explanation of code is given Code replicates results but is verbose or inefficient; Minimal commenting is provided Code replicates results and is efficient; Detailed explanation of code is provided in comments using # notation Results Most of the research questions are not addressed or the results are consistently incomplete or irrelevant Several research questions are not addressed; Numerous results are incomplete, erroneous, or irrelevant 1 or more research questions are not fully addressed; Some results are incomplete or do not to pertain to the questions All research questions are investigated with relevant analyses and figures; Results are clearly stated and not incorrectly or over-interpreted Figures &amp; captions 2 or fewer figures are given; Captions are incomplete or missing 3+ relevant figures are provided but lack proper formatting or completeness; Captions lack numerous details or descriptions 4+ relevant figures are provided with mostly proper formatting; Captions lack some details or descriptions 5+ relevant figures are provided with proper formatting; Captions are included for all figures and contain a title as well as description of axes, other aesthetics, and overall data trends Discussion Synthesis of results is missing or does not pertain to the data; Statements are not supported by the data Conclusions are incomplete or not relevant to the data; Multiple research questions are not addressed or results are incorrectly interpreted Conclusions restate results but without summarization or synthesis across depths; 1 or more questions are not addressed; Some results are incorrectly interpreted Results are summarized within the context of the original questions and more broadly across depths; Results are correctly interpreted and discussed with scientific language; Conclusions are supported by the data and 1 or more future directions are proposed Writing, grammar, &amp; format Grammatical errors, spelling mistakes, and/or language cause significant issues in understanding of the content throughout Numerous grammatical, spelling, or language errors that negatively impact understanding; Some language is overly verbose or informal; One or more sections significantly differ from the recommended length Some grammatical, spelling, or language errors that negatively impact understanding occur; Some language is overly verbose or informal; One section may significantly differ from the recommended length Minimal to no errors; Formal scientific language used throughout; Text flows and is easy to read; Sections adhere to word limits; Report provided in J Bacteriology format 2.6 UJEMI submission Outstanding reports will be invited to submit to The Undergraduate Journal of Experimental Microbiology and Immunology (UJEMI). More information on this will be provided near the end of the Finals Period. "],["background-information.html", "3 Background information 3.1 Project information 3.2 Data collection 3.3 Data availability", " 3 Background information 3.1 Project information Marine oxygen minimum zones (OMZ) are widespread areas of low dissolved oxygen (DO) in subsurface waters. Climate change resulting in increased stratification and reduced oxygen solubility in warming waters leads to an expansion of OMZ. Consequently, the microbial communities shift their metabolism to utilize alternative terminal electron acceptors to adapt to limiting DO conditions. This results in the release of climate active trace gases such as N2O and CH4. OMZs provide useful environmental contexts in which to study coupled biogeochemical cycling through microbial metabolic networks. Coupling ’omics data with biogeochemical data from the OMZs, the regulatory and response dynamics of microbial communities in the OMZs to changing DO levels can be studied. In this study, Saanich inlet, a seasonally anoxic fjord in British Columbia, was used as a model to study microbial community responses to changing DO levels. 3.2 Data collection Multi-omic sequence information from the Saanich Inlet along with geochemical data was collected over six years from the Saanich Inlet. For the context of this tutorial, 90 metagenomes, totalling 4.1 TB of cleaned reads or 16.2 GB of assembled data, were obtained. Please refer Hawley, A. K. et al. (2017) and Torres-Beltrán, M. et al. (2017) 3.3 Data availability "],["introduction-to-anvio.html", "4 Introduction to Anvio 4.1 What is Anvi’o 4.2 Anvi’o installation 4.3 Binning tools installation", " 4 Introduction to Anvio 4.1 What is Anvi’o Analysis and visualization platform for ’omics data, or Anvi’o is an open source platform for analyzing integrated multi-omics data developed by Eren et al. 2015. Anvi’o provides an excellent platform to visualize and analyze multi-omics data. We would use the platform to bin metagenome assembled genomes (MAGs) and manually refine the MAGs. Please visit Anvi’o webpage to learn more about Anvi’o and Anvi’o usage. We would then summarize, or output, the MAGs and perform quality control by estimating the completion and redundancy of the MAGs using CheckM developed by Parks et al. 2015. Later, we would classify the MAGs using GTDB-Tk developed by Chaumeil et al. 2020. 4.2 Anvi’o installation The following instructions provide an overview of commands that should work for most systems. For detailed instructions please see Anvi’o installation resources. Step 1: Please have a working install of miniconda on your terminal. Conda installation of Anvi’o is hassle-free and quick. Make sure the installation is updated by running conda update conda Step 2: For Mac OSX users # first get a copy of the following file (if you get a &quot;command not found&quot; # error for wget, you can either install it first, or manually download the # file from that URL: wget http://merenlab.org/files/anvio-conda-environments/anvio-environment-6.2.yml # just to make sure there is not a v6.2 environment already: conda env remove --name anvio-6.2 # create a new v6.2 environment using the file you just downloaded: conda env create -f anvio-environment-6.2.yml # activate that environment conda activate anvio-6.2 Linux / Windows users: conda create -y --name anvio-6.2 python=3.6 conda activate anvio-6.2 conda install -y -c conda-forge -c bioconda anvio==6.2 Step 3: Confirm installation anvi-self-test --suite mini If all is well, your browser should open and load the test run results 4.3 Binning tools installation While we are installing Anvi’o, we might as well install binning tools that we would use along with Anvi’o. Here we install - METABAT2 developed by Kang et al. 2019 MAXBIN2 developed by Wu et al. 2016 CONCOCT developed by Alneberg et al. 2014 DASTOOL developed by Sieber et al. 2018 # Metabat2 conda install metabat2 # Maxbin2 conda install maxbin2 # Concoct conda install -c bioconda concoct # DAS Tool conda install -c bioconda das\\_tool To verify if these binning tools are accessible by Anvi’o, please run these commands: conda activate anvio-6.2 anvi-cluster-contigs --help You should get a help menu on how to use the binning tools in Anvi’o. If there is a binning tool that is not accessible, you should see [NOT FOUND] next to the binning tool name. If you do not see this tex next to the three binning tools you installed, you are good to proceed. CheckM and GTDB-Tk should be installed on your terminal. "],["anvio-binning-exercise.html", "5 Anvio binning exercise 5.1 Automatic binning on Anvi’o using METABAT2, MAXBIN2, and CONCOCT 5.2 Assessing quality bins 5.3 Manual refinement 5.4 Iterative assessment and refinement", " 5 Anvio binning exercise You will be provided with contigs and merged profiles’ database to run binning and later manual refinement on the bins. Please see this tutorial on assembly-based metagenomics and metagenomic workflow tutorial on Anvi’o to understand how these files were obtained and an in-depth explanation on moving forward. The Anvi’o documentation also provides an excellent commentary on the nuances of each step. 5.1 Automatic binning on Anvi’o using METABAT2, MAXBIN2, and CONCOCT The following commands provide a step by step approach to obtain bins and to load the results on the visualization platform of Anvi’o on your browser for manual refinement. #Create variables for profile and contig databases for easy access to files profile_db = ~/path_to_profile_db contig_db = ~/path_to_contig_db #Make output directory Mkdir ~/path_to_output_directory #Create variable for output directory bin_out=~/path_to_output_directory #Operational parameters threads=32 #Change to suitable amount of threads #Clustering with metabat2 anvi-cluster-contigs -p $profile_db -c $contig_db -C metabat --driver metabat2 -T $threads --just-do-it #Clustering with concoct anvi-cluster-contigs -p $profile_db -c $contig_db -C concoct --driver concoct -T $threads --just-do-it #Clustering with maxbin2 anvi-cluster-contigs -p $profile_db -c $contig_db -C maxbin --driver maxbin2 -T $threads --just-do-it #Consensus binning with DASTOOL anvi-cluster-contigs -p $profile_db -c $contig_db --driver dastool -S metabat,concoct,maxbin -C dastool --just-do-it -T $threads #Obtain bins as fasta files anvi-summarize -p $profile_db -c $contig_db -C dastool -o $bin_out/dastool_out #Copy all bin fasta files for downstream processing such as quality estimation, taxonomic classification, and functional annotation #Make directory for fasta files for easy access mkdir $bin_out/fasta_files cp $bin_out/dastool_out/*/*fasta $bin_out/fasta_files 5.1.1 Note to EDUCE-TA’s In case we want the students to practice manual refinement alone, we can provide them with contaminated bins using Concoct. The following commands creates a fixed number of bins (ideally lower than the actual genomes expected) using Concoct profile_db = ~/path_to_profile_db contig_db = ~/path_to_contig_db #Make output directory Mkdir ~/path_to_output_directory #Operational parameters threads=32 #Change to suitable amount of threads bins=N #Change N to half of the number of bins expected to deliberately contaminate bins and later manually refine them #Clustering with concoct anvi-cluster-contigs -p $profile_db -c $contig_db -C concoct --driver concoct -T $threads --just-do-it --clusters $bins 5.2 Assessing quality bins Check completion and redundancy of MAGs using CheckM. Change paths and operational parameters as required for your system. For a more detailed understanding of how to use CheckM please visit CheckM wiki #Create checkM output directory mkdir ~/path_to_checkm_output_dir #Create variable for output directory checkm_out=~/path_to_checkm_output_dir #Establish bins’ fasta files directory in_fasta=~/path_to_output_fasta_files #Operational parameters – change as required on your system threads=48 pplacer_threads=24 #Run CheckM checkm lineage_wf -t $threads --pplacer_threads $pplacer_threads \\ -f $checkm_out/checkm_out.tsv --tab_table \\ -x fasta $in_fasta $checkm_out/checkm_lineage_wf #checkm_out.tsv is a tab separated file that provides quality estimates on the set of bins 5.2.1 Note the MAG quality Open the tab separated file, checkm_out.tsv in a spreadsheet viewer and study the completion and contamination column. We are looking for high/medium quality MAGs For a detailed commentary on high-quality MAGs, please refer Bowers et al. 2017 For this exercise, we aim to have bins with less than 10 % contamination and more than 50 % completion. We would now use the “anvi-refine” feature to manually refine the bins which have more than 10 % contamination. Please make a note of all the bins which are more than 50 % complete and have more than 10 % contamination. 5.3 Manual refinement Manual refinement on Anvi’o is described in great detail here 5.4 Iterative assessment and refinement After manual refinement of the bins on Anvi’o, iteratively run quality assessment and manual refinement of high contamination bins until you have a list of bins which are more than 90 % complete and less than 10 % contaminated. "],["processing-mags.html", "6 Processing MAGs 6.1 Taxonomic classification using GTDB-Tk", " 6 Processing MAGs Taxonomic classification can be done with GTDB-Tk. GTDB-Tk is a toolkit for using the Genome Taxonomy Database (GTDB) to classify taxonomy of the MAGs. Please read Parks et al. 2018 to learn more about GTDB and Chaumeil et al. 2020 for details on the GTDB-Tk tool. For an in-depth commentary on how to utilize GTDB-Tk please visit https://ecogenomics.github.io/GTDBTk/ After taxonomic classification, functional annotation can be done using TreeSAPP You will be implementing a pipeline called Tree-based Sensitive and Accurate Protein Profiler (TreeSAPP) for automated reconstruction of the nitrogen cycle along defined redox gradients in Saanich Inlet using the Google Cloud Platform. TreeSAPP takes either metagenomic or metatranscriptomic reads and aligns them to previously binned sequence data with each bin representing a putative microbial taxon. TreeSAPP determines three things: A. What taxa are in our metagenomic and metatranscriptomic data represented? B. Which marker genes do these taxa contain (metagenomic data) or actually express (metatranscriptomic data)? C. At what levels are those genes represented (metagenomic data) or expressed by the taxon? Please see the TreeSAPP wiki for more information on treesapp assign, the subcommand you will use. You will be provided with a script template for both the shell and R portion of your analysis (“treesapp_analysis.sh” and “treesapp_analysis.R”) that will guide you as you develop your code. 6.1 Taxonomic classification using GTDB-Tk The following commands will generate taxonomic classification of archaeal and bacterial MAGs #Create GTDB-Tk output directory mkdir ~/path_to_gtdbtk_output_dir #Create variable for output directory gtdbtk_out=~/path_to_gtdb_output_dir #Establish bins’ fasta files directory in_fasta=~/path_to_output_fasta_files #Export GTDB-Tk data path export GTDBTK_DATA_PATH=~/path_to_GTDB_data #Operational parameters – change as required on your system threads=48 pplacer_threads=24 #Run GTDB-Tk gtdbtk classify_wf -x fa --genome_dir $in_fasta \\ --out_dir $gtdbtk_out \\ --cpus $threads \\ --pplacer_cpus $pplacer_threads You would obtain two soft links in the gtdbtk output directory, each for bacteria and archaea taxonomic classification. Please follow the soft link to locate the actual files for taxonomic classification, and download to your system. "],["references-1.html", "7 References", " 7 References Eren, A. M. et al. Anvi’o: an advanced analysis and visualization platform for ’omics data. PeerJ 3, e1319 (2015). Kang, D. D. et al. MetaBAT 2: an adaptive binning algorithm for robust and efficient genome reconstruction from metagenome assemblies. PeerJ 7, e7359 (2019). Wu, Y.-W., Simmons, B. A. &amp; Singer, S. W. MaxBin 2.0: an automated binning algorithm to recover genomes from multiple metagenomic datasets. Bioinformatics 32, 605–607 (2016). Parks, D. H. et al. A standardized bacterial taxonomy based on genome phylogeny substantially revises the tree of life. Nat Biotechnol 36, 996–1004 (2018). Sun, C. L., Thomas, B. C., Barrangou, R. &amp; Banfield, J. F. Metagenomic reconstructions of bacterial CRISPR loci constrain population histories. The ISME Journal 10, 858–870 (2016). Louca, S. et al. Integrating biogeochemistry with multiomic sequence information in a model oxygen minimum zone. PNAS 113, E5925–E5933 (2016). Spang, A. et al. Proposal of the reverse flow model for the origin of the eukaryotic cell based on comparative analyses of Asgard archaeal metabolism. Nature Microbiology 4, 1138–1148 (2019). "]]
