[["index.html", "anvi’o binning and refinement tutorial 1 Introduction 1.1 Guide to the book 1.2 Brief introduction to ’omics methods 1.3 Some key features of metagenomic analysis 1.4 Key points to be aware of and known pitfalls in metagenomics 1.5 Basic outline of a metagenomics pipeline", " anvi’o binning and refinement tutorial Pranav Sampara and Steven Hallam 16/11/2020 1 Introduction The following book provides a basic tutorial and background information for constructing metagenome assembled genomes (MAGs) with manual refinement using anvi’o. The tutorial leverages four binning tools—METABAT2, MAXBIN2, CONCOCT, and DASTool. CheckM is used for MAG quality assessment and GTDB-Tk is used for taxonomic classification. Finally, prokka is used for gene finding and annotation and TreeSAPP is used for fast phylogenetic mapping of functional anchor genes. Collectively, application of these tools is intended to help you answer the following foundational questions: What is the taxonomic and functional structure of the microbial community? How does this structure change along a gradient or in response to environmental perturbation? What are the ecological and biogeochemical consequences of this change? What are relevant units of selection, conservation or utilization within microbial communities? 1.1 Guide to the book An introduction to ’omics methods is provided with a commentary and focus on metagenomics. Typical workflows, key points, and common challenges are described. The next chapter of the book contains the capstone project description and grading rubric as well as information on the data sets to be used for analysis. A brief introduction and installation guide to anvi’o and binning tools follows based on information provided by the Meren lab at the University of Chicago. Finally, example scripts are provided to construct MAGs, conduct taxonomic classification, and complete functional annotations at the individual population and community levels of biological organization. Clearly, this book is a basic introduction to binning and refinement. To maximize the benefit of the tutorial provided, please read the supporting scientific literature wherever provided and look beyond for opportunities to exercise your scientific imagination. 1.2 Brief introduction to ’omics methods 1.3 Some key features of metagenomic analysis Environmental genomics, also known as metagenomics is the study of uncultivated microbial communities in natural and engineered environments using high-throughput sequencing and mass spectrometry methods. Application of metagenomic methods can provide insights into the ecophysiology, ecology and evolution of microorganisms at different levels of biological organization. At the same time these insights can help us uncover design principles for rational design of microbial communities and uncover a deep reservoir of sequence information useful in pathway engineering and biotechnology innovation. Ecophysiology: Enables us to identify who in the community of microorganisms is capable of doing what by linking taxonomic and functional information at the individual, population and community levels of biological organization. Read Spang et al. 2019 Ecology: Estimate community-level properties and interactions between organisms and their environment – richness, diversity, redundancy, degeneracy and resilience. Read Louca et al. 2016 Evolution: Investigate how individuals, populations and communities evolve in response to ecological and environmental state changes with an emphasis on defining ancestry and selective pressures in space and time. Read Sun et al. 2016 1.4 Key points to be aware of and known pitfalls in metagenomics 1.5 Basic outline of a metagenomics pipeline Metagenomic analysis is inherently heterogeneous given the complexity of the input data and the different types of processing steps available. However, certain common steps can be identified that define a conventional workflow consisting of the following processing steps: Quality control, or polishing, of the raw reads Assembly of the raw reads into contiguous sequences, or contigs, and scaffolds Generation of coverage information by mapping the assembled reads to the polished reads Using sequence composition and coverage information to group, or bin, similar contigs. These bins are referred to as metagenome-assembled genomes (MAGs) Quality control of the MAGs to assess completion and contamination Taxonomic classification and functional annotation of MAGs to identify who is present and what their metabolic potential is (see foundation questions in introduction) Metabolic pathway inference to predict given a set of genes what are the likely pathways present at different levels of biological organization. "],["instructions.html", "2 Instructions 2.1 Goal of the exercise 2.2 Project ideas 2.3 Reports and Assessment", " 2 Instructions 2.1 Goal of the exercise The primary objective of this tutorial is to use anvi’o to construct population genome bins, also known as metagenome assembled genomes (MAGs), to identify the taxonomy and metabolic potential of medium to high quality MAGs of interest Bowers et al. 2017. You will be working with metagenomic data sets from the Saanich Inlet time series Cruise #72. Prerequisite input files are provided to construct individual contig and merged profile databases for binning. As indicated above you will be using anvi’o, an ‘omics analysis and visualization platform’ developed by the Meren lab at the University of Chicago. Specific automated binning applications invoked by anvi’o can include MetaBAT2, MaxBin2, CONCOCT, and DAS Tool. Following MAG construciton you will use CheckM to check MAG completeness and contamination and GTDB-Tk to assign taxonomic affiliation. Collectively this information will enable you to reconstruct metabolic networks at the individual, population and community levels of biologicL organization.You will also be using prokka to predict and annotate open reading frames, and BWA to map reads onto MAGs to determine coverage and assess how representative the bins in the sampled community. Results from anvi’o will be compared to those generated using TreeSAPP, an application for fast phylogentic mapping of functional anchor genes, and the subject of a separate tutorial. 2.2 Project ideas Note that these are guiding ideas only. You are welcome to follow your own interests in developing a cogent reporting plan. You are working with primary scientific data and are encouraged to let the science “take you somewhere”. Determine what fraction of reads map to MAGs versus contigs not in MAGs. Are medium to high quality MAGs more or less abundant in the sample based on read mapping? Identify nitrogen cycling genes encoded in MAGs using prokka annotations and compare these results to TreeSAPP annotations using both MAGs and contigs. Are the results equivalent or different? Describe GTDB-Tk assigned taxonomies of MAGs. Can you identify previously described microbial groups based on the published record? Evaluate changes in nitrogen cycling gene taxonomy and abundance at different depths in the Saanich inlet water column with special emphasis on the modular denitrification pathway. How does the frequency distribution of denitrification genes change in relation to oxygen concentration and are there any gaps in pathway representation that are more likely to be filled by a specific taxonoic group? 2.3 Reports and Assessment Reports should be formatted as per the Instructions to Authors for the Journal of Bacteriology. These are roughly equivalent to the JEMI+ reporting guidelines (https://jemi.microbiology.ubc.ca/instructions/submission-guidelines). Reports will account for 20% of the course marks (50 points). The project will be assessed by the following criteria: Completion of the proposed workflow. Expected outputs are available and formatted correctly (40%). A written report (4000 - 4500 words) adhering to the structure below (40%). Five minute oral presentation following the structure of the written report with emphasis on visual analysis of results (20%). Each group will complete one report with the sections listed below. The word counts for each section are recommnedations and can be adjusted as needed, but the topics within each must needs be included! 2.3.1 Abstract (250 word max.) Concisely summarize the major results and implications of the report. 2.3.2 Importance (120 word max.) Lay explanation of the significance of the research performed to the field of environmental microbiology. 2.3.3 Introduction (1250 words) Introduce Saanich Inlet as a model ecosystem for studying microbial community responses to ocean deoxygenation e.g. seasonal cycles, relevant biogeochemistry, nitrogen cycle, relationship to oxygen minimum zones, previous studies, etc. Provide relevant information regarding metagenomic approaches (data generation and application), pros, cons, and alternatives. Introduce one or all of: metagenomic binning, genome assembly, taxonomic profiling. Justify reasoning for using cultivation-independent methods to study microbial metabolic networks e.g. nitrogen cycle. Here we describe “X, Y, Z”. End this section by telling the reader what you are going to tell them. 2.3.4 Methods (750 words) Explain the workflow to generate inputs for the project to show you understand each step. Explain the tools used at each step, and why they were chosen, to answer your group’s specific question. Reference the bash and R(md) scripts containing all commands. Do not include the scripts themselves in the text of your manuscript but submit them as individual files on Canvas. Explain why each step was used, what the outputs are, etc. For example, metagenome assembly was used to build contigs from the quality controlled sequencing reads and used as inputs for binning. Don’t be silly and plagiarise this. Explain any potential deviations from the default parameters or the suggested workflow. 2.3.5 Results (1000 words) Provide a summary of the binning results, CheckM, and GTDB-Tk outputs, as well as those from other software used, if applicable. Explain rationale for focusing on high-quality MAGs but provide information on the total number of bins constructed and their relative abundance based on read mapping. Report on the Prokka annotations such as rRNA predicted, # genes annotated, and potential metabolisms encoded in the medium to high-quality MAGs. Describe the relevant results from your group’s selected project ideas. Explain your experimental logic for each step in the analysis workflow. 2.3.6 Discussion (1000 words) Relate your results back to the introduction. Think about the environmental context and how the obseved taxonmy and function are related to measured geochemical conditions in the Saanich Inlet water column. Consider how each MAG contributes to different metabolic interactions (e.g. denitrification, sulfur oxidation, amino acid biosynthesis, etc). Can you find evidence for distributed metabolism? How do your results compare to previous studies? Are you able to make new observations that expand on prior knowledge? Briefly state any challenges encountered (we know there will be some!) and troubleshooting (parameter or software changes). Do new questions arise from your analysis? If you were to continue working on this proejct what future directions might you take to expand on the work or test specific hypotheses? 2.3.7 Figures and tables (≥4 with captions) Some recommended figures to include: Geochemical gradients for nutrients (phosphate, silicate), nitrogen compounds (nitrate, nitrite, ammonia, nitrous oxide), oxygen and/or sulfur compounds. These are depth-dependent. Scatter plot comparing contamination % (Y-axis) versus completion % (X-axis) between population genome bins. Consider colour coding the bins by taxonomic rank e.g. phylum, order, etc. Indicate high, medium and low contamination bins (see Canvas for an example). RPKM bubble-plot of genes in a pathway versus taxonomy. A diagram showing the taxonomic identity and abundance for each step in the denitrification pathway. A panel of phylogenetic trees showing the depth specific trends for selected TreeSAPP reference packages. 2.3.8 References (&gt;20) Necessary citations include: Each software application used (including those in the provided bash scripts (MEGAHIT, MetaBAT, CheckM, etc.). Make sure you include version numbers in your methods and indicate parameter settings used e.g. default. Relevant papers from Saanich Inlet or other marine oxygen minimum zones. 2.3.9 Fin. This evaluation rubric should serve as a useful scaffold for your group. How you expand on it will depend on your combined interests and analytic choices. Let the science take you somewhere! 2.3.10 UJEMI submission Outstanding reports will be invited to submit to The Undergraduate Journal of Experimental Microbiology and Immunology (UJEMI). "],["background-information.html", "3 Background information 3.1 Project information 3.2 Data collection 3.3 Data availability", " 3 Background information 3.1 Project information Marine oxygen minimum zones (OMZ) are widespread areas of low dissolved oxygen (DO) in subsurface waters. Climate change resulting in increased stratification and reduced oxygen solubility in warming waters leads to an expansion of OMZ. Consequently as oxygen levels decline, the microbial communities inhabiting OMZ waters shift their metabolisms to utilize alternative terminal electron acceptors. This results in the production of climate active trace gases such as nitrous oxide (N2O) and methane (CH4). OMZs provide useful environmental contexts in which to study coupled biogeochemical cycling through microbial metabolic networks. By combining ’omics data with biogeochemical data from OMZs it becomes possible to evaluate regulatory and response dynamics of microbial communities to changing DO levels. In this study, Saanich inlet, a seasonally anoxic fjord on the coast of Vancouver Island British Columbia, was used as a model ecosystem to study microbial community responses to changing DO levels. 3.2 Data collection Multi-omic sequence information (DNA, RNA and proteins) from Saanich Inlet along with geochemical parameter information was collected over many years prodicing a time series record of recurring water column stratificaiton and deep water renewal. For this tutorial, 90 metagenomes spanning water colum redix gradients in space and time, totalling 4.1 TB of cleaned reads or 16.2 GB of assembled data, were prepared. (a) Oxygen concentration contour for CTD data (February 2008 onward)35 indicating 16 sampling depths for water column geochemistry and high-resolution (HR) DNA samples for SSU libraries (small black dots) and six major depths for large volume (LV) samples for meta-genomics, -transcriptomics, -proteomics and LV SSU libraries (large black dots). (b) Sample inventory from February 2006 to October 2014 indicating multi-omic datasets included in this manuscript (solid black), in previous publications (gray) and accompanying datasets currently undergoing processing and analysis (open gray). Please refer Hawley, A. K. et al. (2017) and Torres-Beltrán, M. et al. (2017) 3.3 Data availability "],["introduction-to-anvio.html", "4 Introduction to anvi’o 4.1 What is anvi’o 4.2 anvi’o installation 4.3 Binning tools installation 4.4 Automatic binning on anvi’o using METABAT2, MAXBIN2, and CONCOCT 4.5 Assessing quality MAGs 4.6 Manual refinement 4.7 Iterative assessment and refinement", " 4 Introduction to anvi’o 4.1 What is anvi’o Analysis and visualization platform for ’omics data, or anvi’o was developed by Eren et al. 2015 at the University of Chicago. Anvi’o is an open source platform for analyzing integrated multi-omics data and provides a useful and intiutive framework for constructing and curating metagenome assebled genomes (MAGs) In this tutorial we will use anvi’o to constrcut metagenome assembled genomes (MAGs) from the Saanich Inlet water column with manual refinement. Please visit anvi’o webpage to learn more about the platform and its usage. After constructing MAGs from several depth intervals you will perform quality control by estimating completion and contamination using CheckM developed by Parks et al. 2015. You will then classify medium to high-quality MAGs Bowers et al. 2017 using GTDB-Tk developed by Chaumeil et al. 2020. 4.2 anvi’o installation The following instructions based on documentation provided by the Meren lab provide an overview of commands that should work for most operating systems. For detailed instructions please see anvi’o installation resources. Step 1: Please have a working install of miniconda on your terminal. Conda installation of anvi’o is hassle-free and quick. Make sure the installation is updated by running conda update conda Step 2: For Mac OSX users # first get a copy of the following file (if you get a &quot;command not found&quot; # error for wget, you can either install it first, or manually download the # file from that URL: wget http://merenlab.org/files/anvio-conda-environments/anvio-environment-6.2.yml # just to make sure there is not a v6.2 environment already: conda env remove --name anvio-6.2 # create a new v6.2 environment using the file you just downloaded: conda env create -f anvio-environment-6.2.yml # activate that environment conda activate anvio-6.2 Linux / Windows users: conda create -y --name anvio-6.2 python=3.6 conda activate anvio-6.2 conda install -y -c conda-forge -c bioconda anvio==6.2 Step 3: Confirm installation anvi-self-test --suite mini If all is well, your browser should open and load the test run results 4.3 Binning tools installation While we are installing anvi’o, we might as well install binning tools needed to construct MAGs. Here we install - METABAT2 developed by Kang et al. 2019 MAXBIN2 developed by Wu et al. 2016 CONCOCT developed by Alneberg et al. 2014 DASTOOL developed by Sieber et al. 2018 # Metabat2 conda install metabat2 # Maxbin2 conda install maxbin2 # Concoct conda install -c bioconda concoct # DAS Tool conda install -c bioconda das\\_tool To verify if these binning tools are accessible by anvi’o, please run these commands: conda activate anvio-6.2 anvi-cluster-contigs --help You should get a help menu on how to use the binning tools in anvi’o. If there is a binning tool that is not accessible, you should see [NOT FOUND] next to the binning tool name. If you do not see this tex next to the three binning tools you installed, you are good to proceed. CheckM (https://anaconda.org/bioconda/checkm-genome) and GTDB-Tk (https://anaconda.org/bioconda/gtdbtk) should also be installed on your terminal. #anvi’o binning exercise You will be provided with fastq files, contig and merged profile databases to construct MAGs and conduct manual refinement. Please see this tutorial on assembly-based metagenomics and metagenomic workflow tutorial on anvi’o to understand how these files were obtained and an in-depth explanation on moving forward. The anvi’o documentation also provides an excellent commentary on the nuances of each step. Additional course material relevant to this tutorial can be found in the lecture slides describing metagenome assembled genomes. 4.4 Automatic binning on anvi’o using METABAT2, MAXBIN2, and CONCOCT The following commands provide a step by step approach to obtain MAGs and to load the results on the visualization platform of anvi’o on your browser for manual refinement. #Create variables for profile and contig databases for easy access to files profile_db = ~/path_to_profile_db contig_db = ~/path_to_contig_db #Make output directory Mkdir ~/path_to_output_directory #Create variable for output directory bin_out=~/path_to_output_directory #Operational parameters threads=32 #Change to suitable amount of threads #Clustering with metabat2 anvi-cluster-contigs -p $profile_db -c $contig_db -C metabat --driver metabat2 -T $threads --just-do-it #Clustering with concoct anvi-cluster-contigs -p $profile_db -c $contig_db -C concoct --driver concoct -T $threads --just-do-it #Clustering with maxbin2 anvi-cluster-contigs -p $profile_db -c $contig_db -C maxbin --driver maxbin2 -T $threads --just-do-it #Consensus binning with DASTOOL anvi-cluster-contigs -p $profile_db -c $contig_db --driver dastool -S metabat,concoct,maxbin -C dastool --just-do-it -T $threads #Obtain bins as fasta files anvi-summarize -p $profile_db -c $contig_db -C dastool -o $bin_out/dastool_out #Copy all bin fasta files for downstream processing such as quality estimation, taxonomic classification, and functional annotation #Make directory for fasta files for easy access mkdir $bin_out/fasta_files cp $bin_out/dastool_out/*/*fasta $bin_out/fasta_files 4.4.1 Note to EDUCE-TA’s In case we want the students to practice manual refinement alone, we can provide them with contaminated MAGs using Concoct. The following commands creates a fixed number of MAGs (ideally lower than the actual genomes expected) using Concoct profile_db = ~/path_to_profile_db contig_db = ~/path_to_contig_db #Make output directory Mkdir ~/path_to_output_directory #Operational parameters threads=32 #Change to suitable amount of threads bins=N #Change N to half of the number of bins expected to deliberately contaminate bins and later manually refine them #Clustering with concoct anvi-cluster-contigs -p $profile_db -c $contig_db -C concoct --driver concoct -T $threads --just-do-it --clusters $bins 4.5 Assessing quality MAGs Check completion and redundancy of MAGs using CheckM. Change paths and operational parameters as required for your system. For a more detailed understanding of how to use CheckM please visit CheckM wiki #Create checkM output directory mkdir ~/path_to_checkm_output_dir #Create variable for output directory checkm_out=~/path_to_checkm_output_dir #Establish bins’ fasta files directory in_fasta=~/path_to_output_fasta_files #Operational parameters – change as required on your system threads=48 pplacer_threads=24 #Run CheckM checkm lineage_wf -t $threads --pplacer_threads $pplacer_threads \\ -f $checkm_out/checkm_out.tsv --tab_table \\ -x fasta $in_fasta $checkm_out/checkm_lineage_wf #checkm_out.tsv is a tab separated file that provides quality estimates on the set of bins 4.5.1 Note the MAG quality Open the tab separated file, checkm_out.tsv in a spreadsheet viewer and study the completion and contamination column. We are looking for medium to high-quality MAGs Bowers et al. 2017. For this exercise, we aim to have bins with less than 10 % contamination and more than 50 % completion. We will now use the “anvi-refine” feature to manually refine the bins which have more than 10 % contamination. Please make a note of all the bins which are more than 50 % complete and have more than 10 % contamination. 4.6 Manual refinement Manual refinement on anvi’o is described in great detail here 4.7 Iterative assessment and refinement After manual refinement of the bins using anvi’o, iteratively run quality assessment and manual refinement of high contamination bins until you have a list of bins which are more than 90 % complete and less than 10 % contaminated. "],["processing-mags.html", "5 Processing MAGs 5.1 Taxonomic classification using GTDB-Tk", " 5 Processing MAGs Taxonomic classification can be done with GTDB-Tk. GTDB-Tk is a toolkit for using the Genome Taxonomy Database (GTDB) to classify taxonomy of the MAGs. Please read Parks et al. 2018 to learn more about GTDB and Chaumeil et al. 2020 for details on the GTDB-Tk tool. For an in-depth commentary on how to utilize GTDB-Tk please visit https://ecogenomics.github.io/GTDBTk/ After taxonomic classification, functional annotation can be done using different applications including prokka or TreeSAPP. Here, you will be implementing the Tree-based Sensitive and Accurate Protein Profiler (TreeSAPP) for automated reconstruction of the nitrogen cycle along defined redox gradients in Saanich Inlet. TreeSAPP takes either metagenomic or metatranscriptomic reads and aligns them to previously binned sequence data with each bin representing a putative microbial taxon. TreeSAPP determines three things: A. What taxa are represented in the metagenomic or metatranscriptomic sample? B. Which marker genes do these taxa encode (metagenomic data) or express (metatranscriptomic data)? C. At what levels are these genes present (metagenomic data) or expressed in the sample? Please see the TreeSAPP wiki for more information on treesapp assign, the subcommand you will use. You will be provided with a script template for both the shell and R portion of your analysis (“treesapp_analysis.sh” and “treesapp_analysis.R”) that will guide you as you develop your code. 5.1 Taxonomic classification using GTDB-Tk The following commands will generate taxonomic classification of archaeal and bacterial MAGs #Create GTDB-Tk output directory mkdir ~/path_to_gtdbtk_output_dir #Create variable for output directory gtdbtk_out=~/path_to_gtdb_output_dir #Establish bins’ fasta files directory in_fasta=~/path_to_output_fasta_files #Export GTDB-Tk data path export GTDBTK_DATA_PATH=~/path_to_GTDB_data #Operational parameters – change as required on your system threads=48 pplacer_threads=24 #Run GTDB-Tk gtdbtk classify_wf -x fa --genome_dir $in_fasta \\ --out_dir $gtdbtk_out \\ --cpus $threads \\ --pplacer_cpus $pplacer_threads You will obtain two soft links in the gtdbtk output directory, each for bacteria and archaea taxonomic classification. Please follow the soft link to locate the actual files for taxonomic classification, and download to your system. "],["references.html", "6 References", " 6 References Eren, A. M. et al. Anvi’o: an advanced analysis and visualization platform for ’omics data. PeerJ 3, e1319 (2015). Kang, D. D. et al. MetaBAT 2: an adaptive binning algorithm for robust and efficient genome reconstruction from metagenome assemblies. PeerJ 7, e7359 (2019). Wu, Y.-W., Simmons, B. A. &amp; Singer, S. W. MaxBin 2.0: an automated binning algorithm to recover genomes from multiple metagenomic datasets. Bioinformatics 32, 605–607 (2016). Parks, D. H. et al. A standardized bacterial taxonomy based on genome phylogeny substantially revises the tree of life. Nat Biotechnol 36, 996–1004 (2018). Sun, C. L., Thomas, B. C., Barrangou, R. &amp; Banfield, J. F. Metagenomic reconstructions of bacterial CRISPR loci constrain population histories. The ISME Journal 10, 858–870 (2016). Louca, S. et al. Integrating biogeochemistry with multiomic sequence information in a model oxygen minimum zone. PNAS 113, E5925–E5933 (2016). Spang, A. et al. Proposal of the reverse flow model for the origin of the eukaryotic cell based on comparative analyses of Asgard archaeal metabolism. Nature Microbiology 4, 1138–1148 (2019). "]]
