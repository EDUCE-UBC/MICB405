<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Protocol and scripts | anvi’o binning and refinement tutorial</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Protocol and scripts | anvi’o binning and refinement tutorial" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Protocol and scripts | anvi’o binning and refinement tutorial" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Pranav Sampara, Steven Hallam, Stefanie Christen Sternagel, Julia Anstett, Stephan Koenig" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="processing-mags.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">anvi'o binning and refinement tutorial</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#guide-to-the-book"><i class="fa fa-check"></i><b>1.1</b> Guide to the book</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#some-key-features-of-metagenomic-analysis"><i class="fa fa-check"></i><b>1.2</b> Some key features of metagenomic analysis</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#basic-outline-of-a-metagenomics-pipeline"><i class="fa fa-check"></i><b>1.3</b> Basic outline of a metagenomics pipeline</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="instructions.html"><a href="instructions.html"><i class="fa fa-check"></i><b>2</b> Instructions</a><ul>
<li class="chapter" data-level="2.1" data-path="instructions.html"><a href="instructions.html#goal-of-the-exercise"><i class="fa fa-check"></i><b>2.1</b> Goal of the exercise</a></li>
<li class="chapter" data-level="2.2" data-path="instructions.html"><a href="instructions.html#project-ideas"><i class="fa fa-check"></i><b>2.2</b> Project ideas</a></li>
<li class="chapter" data-level="2.3" data-path="instructions.html"><a href="instructions.html#reports-and-assessment"><i class="fa fa-check"></i><b>2.3</b> Reports and Assessment</a><ul>
<li class="chapter" data-level="2.3.1" data-path="instructions.html"><a href="instructions.html#abstract-250-word-max."><i class="fa fa-check"></i><b>2.3.1</b> Abstract (250 word max.)</a></li>
<li class="chapter" data-level="2.3.2" data-path="instructions.html"><a href="instructions.html#importance-120-word-max."><i class="fa fa-check"></i><b>2.3.2</b> Importance (120 word max.)</a></li>
<li class="chapter" data-level="2.3.3" data-path="instructions.html"><a href="instructions.html#introduction-1250-words"><i class="fa fa-check"></i><b>2.3.3</b> Introduction (1250 words)</a></li>
<li class="chapter" data-level="2.3.4" data-path="instructions.html"><a href="instructions.html#methods-750-words"><i class="fa fa-check"></i><b>2.3.4</b> Methods (750 words)</a></li>
<li class="chapter" data-level="2.3.5" data-path="instructions.html"><a href="instructions.html#results-1000-words"><i class="fa fa-check"></i><b>2.3.5</b> Results (1000 words)</a></li>
<li class="chapter" data-level="2.3.6" data-path="instructions.html"><a href="instructions.html#discussion-1000-words"><i class="fa fa-check"></i><b>2.3.6</b> Discussion (1000 words)</a></li>
<li class="chapter" data-level="2.3.7" data-path="instructions.html"><a href="instructions.html#figures-and-tables-4-with-captions"><i class="fa fa-check"></i><b>2.3.7</b> Figures and tables (≥4 with captions)</a></li>
<li class="chapter" data-level="2.3.8" data-path="instructions.html"><a href="instructions.html#references-20"><i class="fa fa-check"></i><b>2.3.8</b> References (&gt;20)</a></li>
<li class="chapter" data-level="2.3.9" data-path="instructions.html"><a href="instructions.html#fin."><i class="fa fa-check"></i><b>2.3.9</b> Fin.</a></li>
<li class="chapter" data-level="2.3.10" data-path="instructions.html"><a href="instructions.html#ujemi-submission"><i class="fa fa-check"></i><b>2.3.10</b> UJEMI submission</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="background-information.html"><a href="background-information.html"><i class="fa fa-check"></i><b>3</b> Background information</a><ul>
<li class="chapter" data-level="3.1" data-path="background-information.html"><a href="background-information.html#project-information"><i class="fa fa-check"></i><b>3.1</b> Project information</a></li>
<li class="chapter" data-level="3.2" data-path="background-information.html"><a href="background-information.html#data-collection"><i class="fa fa-check"></i><b>3.2</b> Data collection</a></li>
<li class="chapter" data-level="3.3" data-path="background-information.html"><a href="background-information.html#data-availability"><i class="fa fa-check"></i><b>3.3</b> Data availability</a></li>
<li class="chapter" data-level="3.4" data-path="background-information.html"><a href="background-information.html#preliminary-data-processing"><i class="fa fa-check"></i><b>3.4</b> Preliminary data processing</a><ul>
<li class="chapter" data-level="3.4.1" data-path="background-information.html"><a href="background-information.html#quality-filtering-of-reads"><i class="fa fa-check"></i><b>3.4.1</b> Quality filtering of reads</a></li>
<li class="chapter" data-level="3.4.2" data-path="background-information.html"><a href="background-information.html#assembly"><i class="fa fa-check"></i><b>3.4.2</b> Assembly</a></li>
<li class="chapter" data-level="3.4.3" data-path="background-information.html"><a href="background-information.html#deduplication"><i class="fa fa-check"></i><b>3.4.3</b> Deduplication</a></li>
<li class="chapter" data-level="3.4.4" data-path="background-information.html"><a href="background-information.html#mapping"><i class="fa fa-check"></i><b>3.4.4</b> Mapping</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introduction-to-anvio.html"><a href="introduction-to-anvio.html"><i class="fa fa-check"></i><b>4</b> Introduction to anvi’o</a><ul>
<li class="chapter" data-level="4.1" data-path="introduction-to-anvio.html"><a href="introduction-to-anvio.html#what-is-anvio"><i class="fa fa-check"></i><b>4.1</b> What is anvi’o</a></li>
<li class="chapter" data-level="4.2" data-path="introduction-to-anvio.html"><a href="introduction-to-anvio.html#anvio-installation"><i class="fa fa-check"></i><b>4.2</b> anvi’o installation</a></li>
<li class="chapter" data-level="4.3" data-path="introduction-to-anvio.html"><a href="introduction-to-anvio.html#binning-tools-installation"><i class="fa fa-check"></i><b>4.3</b> Binning tools installation</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="anvio-binning-exercise.html"><a href="anvio-binning-exercise.html"><i class="fa fa-check"></i><b>5</b> anvi’o binning exercise</a><ul>
<li class="chapter" data-level="5.1" data-path="anvio-binning-exercise.html"><a href="anvio-binning-exercise.html#automatic-binning-on-anvio-using-metabat2-maxbin2-and-concoct"><i class="fa fa-check"></i><b>5.1</b> Automatic binning on anvi’o using METABAT2, MAXBIN2, and CONCOCT</a><ul>
<li class="chapter" data-level="5.1.1" data-path="anvio-binning-exercise.html"><a href="anvio-binning-exercise.html#note-to-educe-tas"><i class="fa fa-check"></i><b>5.1.1</b> Note to EDUCE-TA’s</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="anvio-binning-exercise.html"><a href="anvio-binning-exercise.html#assessing-quality-mags"><i class="fa fa-check"></i><b>5.2</b> Assessing quality MAGs</a><ul>
<li class="chapter" data-level="5.2.1" data-path="anvio-binning-exercise.html"><a href="anvio-binning-exercise.html#note-the-mag-quality"><i class="fa fa-check"></i><b>5.2.1</b> Note the MAG quality</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="anvio-binning-exercise.html"><a href="anvio-binning-exercise.html#manual-refinement"><i class="fa fa-check"></i><b>5.3</b> Manual refinement</a></li>
<li class="chapter" data-level="5.4" data-path="anvio-binning-exercise.html"><a href="anvio-binning-exercise.html#iterative-assessment-and-refinement"><i class="fa fa-check"></i><b>5.4</b> Iterative assessment and refinement</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="processing-mags.html"><a href="processing-mags.html"><i class="fa fa-check"></i><b>6</b> Processing MAGs</a><ul>
<li class="chapter" data-level="6.1" data-path="processing-mags.html"><a href="processing-mags.html#taxonomic-classification-using-gtdb-tk"><i class="fa fa-check"></i><b>6.1</b> Taxonomic classification using GTDB-Tk</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html"><i class="fa fa-check"></i><b>7</b> Protocol and scripts</a><ul>
<li class="chapter" data-level="7.1" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#project-files"><i class="fa fa-check"></i><b>7.1</b> Project files</a></li>
<li class="chapter" data-level="7.2" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#quality-filtering-and-assembly"><i class="fa fa-check"></i><b>7.2</b> Quality filtering and assembly</a></li>
<li class="chapter" data-level="7.3" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#deduplication-of-contigs"><i class="fa fa-check"></i><b>7.3</b> Deduplication of contigs</a></li>
<li class="chapter" data-level="7.4" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#prokka-annotation"><i class="fa fa-check"></i><b>7.4</b> Prokka annotation</a></li>
<li class="chapter" data-level="7.5" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#mapping-1"><i class="fa fa-check"></i><b>7.5</b> Mapping</a></li>
<li class="chapter" data-level="7.6" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#create-anvio-databases"><i class="fa fa-check"></i><b>7.6</b> Create anvi’o databases</a><ul>
<li class="chapter" data-level="7.6.1" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#building-contigs-database"><i class="fa fa-check"></i><b>7.6.1</b> Building contigs database</a></li>
<li class="chapter" data-level="7.6.2" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#building-profile-databases"><i class="fa fa-check"></i><b>7.6.2</b> Building profile databases</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#binning"><i class="fa fa-check"></i><b>7.7</b> Binning</a></li>
<li class="chapter" data-level="7.8" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#assess-genome-quality-with-checkm-and-manual-refinement"><i class="fa fa-check"></i><b>7.8</b> Assess genome quality with CheckM and manual refinement</a><ul>
<li class="chapter" data-level="7.8.1" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#checkm-usage"><i class="fa fa-check"></i><b>7.8.1</b> CheckM usage</a></li>
<li class="chapter" data-level="7.8.2" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#manual-refinement-1"><i class="fa fa-check"></i><b>7.8.2</b> Manual refinement</a></li>
<li class="chapter" data-level="7.8.3" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#iterative-assessment-and-refinement-1"><i class="fa fa-check"></i><b>7.8.3</b> Iterative assessment and refinement</a></li>
<li class="chapter" data-level="7.8.4" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#store-bins-on-the-server"><i class="fa fa-check"></i><b>7.8.4</b> Store bins on the server</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#assigning-gtdb-taxonomy-to-your-bins"><i class="fa fa-check"></i><b>7.9</b> Assigning GTDB taxonomy to your bins</a></li>
<li class="chapter" data-level="7.10" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#make-sure-to-echo-the-gtdb-tk-data-pathecho"><i class="fa fa-check"></i><b>7.10</b> Make sure to echo the GTDB-Tk data pathecho</a></li>
<li class="chapter" data-level="7.11" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#working-with-treesapp"><i class="fa fa-check"></i><b>7.11</b> Working with TreeSAPP</a></li>
<li class="chapter" data-level="7.12" data-path="protocol-and-scripts.html"><a href="protocol-and-scripts.html#treesapp-script"><i class="fa fa-check"></i><b>7.12</b> TreeSAPP script</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>8</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">anvi’o binning and refinement tutorial</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="protocol-and-scripts" class="section level1">
<h1><span class="header-section-number">7</span> Protocol and scripts</h1>
<p>The following scripts and commands were used in the generation of the files available for data processing.</p>
<p>In short, the protocol used is:</p>
<ol style="list-style-type: decimal">
<li>Quality filter reads with Trimmomatic (v.0.35) (<a href="https://doi.org/10.1093/bioinformatics/btu170">Bolger et al., (2014)</a>).</li>
<li>Assemble QC reads Megahit (v.1.1.3) (<a href="https://doi.org/10.1093/bioinformatics/btv033">Li et al., (2015)</a>)</li>
<li>Annotate contigs with Prokka.</li>
<li>Deduplicate contigs with BBtools (<a href="https://jgi.doe.gov/data-and-tools/bbtools/">BBtools</a>).</li>
<li>Map the deduplicated contigs to the QC reads with bwa-mem (<a href="https://arxiv.org/pdf/1303.3997.pdf">Li H. (2013)</a>).</li>
<li>Create anvi’o contigs and profile databases (<a href="https://peerj.com/articles/1319/">Eren et al. 2015</a>).</li>
<li>Construct metagenome-assembled genomes (MAGs) using binning tools such as Metabat2 (<a href="https://peerj.com/articles/7359/">Kang et al. 2019</a>), Maxbin2 (<a href="https://academic.oup.com/bioinformatics/article/32/4/605/1744462">Wu et al. 2016</a>), Concoct (<a href="https://www.nature.com/articles/nmeth.3103">Alneberg et al. 2014</a>), and DASTool (<a href="https://www.nature.com/articles/s41564-018-0171-1">Sieber et al. 2018</a>).</li>
<li>Use CheckM (<a href="https://genome.cshlp.org/content/25/7/1043">Parks et al. 2015</a>) for estimating genome completion and contamination.</li>
<li>Revisit anvi’o for manual refinement using the program <code>anvi-refine</code></li>
<li>Identify taxonomy using GTDB-Tk (<a href="https://academic.oup.com/bioinformatics/article/36/6/1925/5626182">Chaumeil et al. 2020</a>).</li>
<li>Downstream processing of MAGs using TreeSAPP (<a href="https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btaa588/5868555">Morgan-Lang et al. 2020</a>) to identify genes and functions of interest.</li>
</ol>
<div id="project-files" class="section level2">
<h2><span class="header-section-number">7.1</span> Project files</h2>
<p>In case you are stuck and need to access project files, please look through the file structure system, <a href="project_structure_level.txt"><code>project_structure_level.txt</code></a>.</p>
<p>The path to the project files -
<code>/projects/micb405/resources/metagenomics_data/MICB405_Project_Files</code></p>
</div>
<div id="quality-filtering-and-assembly" class="section level2">
<h2><span class="header-section-number">7.2</span> Quality filtering and assembly</h2>
<p>Quality filtered reads and assembled contigs are available on the server. Quality filtering was performed using Trimmomatic and Assembly was performed using Megahit.</p>
</div>
<div id="deduplication-of-contigs" class="section level2">
<h2><span class="header-section-number">7.3</span> Deduplication of contigs</h2>
<p><code>dedupe.sh in=SI072_Combined_contigs.fa out=SI072_Dedupe_Contigs.fa outd=duplicates.fa</code></p>
</div>
<div id="prokka-annotation" class="section level2">
<h2><span class="header-section-number">7.4</span> Prokka annotation</h2>
<p>If you want to leverage the anvi-import-function with Prokka annotations, you will need to do this first. Prokka takes a long time to run, but this needs to happen first before you had anything over to the students. This protocol follows tutorial listed <a href="http://merenlab.org/2017/05/18/working-with-prokka/">here</a>.</p>
<p>Download and install the following:</p>
<pre><code>wget https://raw.githubusercontent.com/karkman/gff_parser/master/gff_parser.py -O gff_parser.py`

pip install gffutils</code></pre>
<p>Before you begin, you’ll need to modify the Prokka code a little bit before running the tool to ensure you get partial gene calls from Prodigal since we’re working with metagenomes. For Prokka v1.14.6 you’ll want to take away the -c flag on line 717 of the prodigal command.</p>
<p>Run Prokka on your deduplicated combined assembly:</p>
<p><code>prokka --prefix PROKKA --outdir PROKKA --cpus 4 --metagenome  SI072_Dedupe_Contigs.fa</code></p>
<p>Prokka takes a really long time to run, but you only really need the <code>.gff</code> file that it produces. Once the job gets to the tbl2asn step, just kill it (it will make you cry inside, but it’ll be fine I promise! Have solace in knowing that there’s a good chance that it would have crashed on its own anyway).
Next you’ll use that custom script you just downloaded and installed:</p>
<p><code>python gff_parser.py PROKKA/PROKKA.gff --gene-calls gene_calls.txt  --annotation gene_annot.txt</code></p>
<p>This script parses the gff file to give you the inputs that you’ll need. However, as of <code>anvio-6.2</code>, this script produces an extra column in the gene-calls.txt file that is no longer accepted when you try to build the contig database (it’s column labeled call_type) and it’s the 7th one in from the left. The quickest way I dealt with it was to use the cut command:</p>
<p><code>cut -f1,2,3,4,5,6,8,9 path/PROKKA/BAC_gene_calls.txt &gt; path/PROKKA/BAC_gene_call_fixed.txt</code></p>
</div>
<div id="mapping-1" class="section level2">
<h2><span class="header-section-number">7.5</span> Mapping</h2>
<p>This step can happen in parallel with running Prokka or building your contigs database if you have the RAM, but as long as this happens before you make your profile databases, you’ll be fine.</p>
<p>First, you need to index the input fasta file:</p>
<p><code>bwa index SI072_Dedupe_Contigs.fa</code></p>
<p>Then follow the following steps for each sample:</p>
<p><code>bwa mem -t 4 SI072_Dedupe_Contigs.fa SI072_(depth_here)m_raw_reads.fastq.gz | samtools view -b | samtools sort -o SI072_(depth_here)m_Dedupe_contigs_sorted.bam</code></p>
<p><code>samtools view -b -F 4 SI072_(depth_here)m_Dedupe_contigs_sorted.bam &gt; SI072_(depth_here)m_Dedupe_contigs_sorted.mapped.bam</code></p>
<p><code>samtools index SI072_(depth_here)m_Dedupe_contigs_sorted.mapped.bam</code></p>
</div>
<div id="create-anvio-databases" class="section level2">
<h2><span class="header-section-number">7.6</span> Create anvi’o databases</h2>
<p>You would need to create a contigs database to store all information related to the contigs and a profile database to store sample specific information about the contigs.</p>
<div id="building-contigs-database" class="section level3">
<h3><span class="header-section-number">7.6.1</span> Building contigs database</h3>
<p><code>anvi-gen-contigs-database -f SI072_Dedupe_Contigs.fa -o SI072_Dedupe_contigs.db  --external-gene-calls Prokka_to_Anvio/BAC_gene_calls_fixed.txt -n 'SI072 100m,120m, 200m with Prokka' --ignore-internal-stop-codons</code></p>
<p><code>anvi-import-functions -c SI072_Dedupe_contigs.db -i Prokka_to_Anvio/BAC_gene_annot.txt</code></p>
<p><code>anvi-run-hmms -c SI072_Dedupe_contigs.db --num-threads 8</code></p>
<p>You could annotate the contigs with NCBI cogs, but since we used Prokka, we will skip any more annotation.</p>
</div>
<div id="building-profile-databases" class="section level3">
<h3><span class="header-section-number">7.6.2</span> Building profile databases</h3>
<p>Since you’ve already gone through the trouble of building up your bam and bam.bai files, you can skip right ahead to the anvi-profile step, note that the minimum contig length cut-off is 2000 bp:</p>
<p><code>anvi-profile -i SI072_(depth_here)m_Dedupe_contigs_sorted.mapped.bam -c SI072_Dedupe_contigs.db --min-contig-length 2000 --output-dir SI072_(Depth)_Profile --sample-name “sample_name”</code> #Assign your sample name</p>
<p>Do this for each sample. You could run a for loop to ease through</p>
<p>Next, merge the profiles together:</p>
<p><code>anvi-merge *Profile/PROFILE.db -o SI072_MERGED -c SI072_Dedupe_contigs.db --sample-name SI072</code></p>
</div>
</div>
<div id="binning" class="section level2">
<h2><span class="header-section-number">7.7</span> Binning</h2>
<p>Once anvio can see your binnning tools, it’s time to make some bins with concoct, maxbin2, and metabat2. Its very important that you set the minimum contig length is the same as your profile db, some of the binning algorithms fail if you don’t</p>
<p><code>anvi-cluster-contigs -p SI072_MERGED/PROFILE.db -c SI072_Dedupe_contigs.db -C maxbin2 --driver maxbin2 -T 8 --min-contig-length 2000 --just-do-it</code></p>
<p><code>anvi-cluster-contigs -p SI072_MERGED/PROFILE.db -c SI072_Dedupe_contigs.db -C maxbin2 --driver maxbin2 -T 8 --min-contig-length 2000 --just-do-it</code></p>
<p><code>anvi-cluster-contigs -p SI072_MERGED_Profile/PROFILE.db -c SI072_Dedupe_contigs.db -C maxbin2 --driver maxbin2 -T 8 --min-contig-length 2000 --just-do-it</code></p>
<p>Now we can use dastool to consolidate these bins:</p>
<p><code>anvi-cluster-contigs -p SI072_MERGED_Profile/PROFILE.db -c SI072_Dedupe_contigs.db -C dastool --driver dastool -T 8 --just-do-it -S concoct,metabat2,maxbin2</code></p>
<p>Now that we’ve got some bins with dastool, it’s time to grab the fasta files. First, you need to make a summary directory:</p>
<p><code>anvi-summarize -p SI072_MERGED_Profile/PROFILE.db -c SI072_Dedupe_contigs.db -o SI072_SUMMARY_MERGE_Pre_Ref -C dastool</code></p>
<p>make a directory to put the fasta files to put your bins into</p>
<p><code>mkdir SI072_Bins_Pre_Man</code></p>
<p>Copy the fasta files into your new directory:</p>
<p><code>cp SI072_SUMMARY_MERGE_Pre_Ref/bin_by_bin/*/*.fa SI072_Bins_Pre_Man</code></p>
</div>
<div id="assess-genome-quality-with-checkm-and-manual-refinement" class="section level2">
<h2><span class="header-section-number">7.8</span> Assess genome quality with CheckM and manual refinement</h2>
<div id="checkm-usage" class="section level3">
<h3><span class="header-section-number">7.8.1</span> CheckM usage</h3>
<p><code>checkm lineage_wf -t 8 --pplacer_threads 8 -f SI072_Bins_Pre_Man /SI072_Bins_ Pre_Man_CheckM.tsv --tab_table -x .fa SI072_Bins_Pre_Man/ SI072_Pre_Man/checkm_output</code></p>
<p>Open the tab separated file, checkm_out.tsv in a spreadsheet viewer and study the completion and contamination column. We are looking for medium to high-quality MAGs <a href="https://rdcu.be/b9JqO">Bowers et al. 2017</a>.</p>
<p>For this exercise, we aim to have bins with less than 10 % contamination and more than 50 % completion. We will now use the “anvi-refine” feature to manually refine the bins which have more than 10 % contamination. Please make a note of all the bins which are more than 50 % complete and have more than 10 % contamination.</p>
</div>
<div id="manual-refinement-1" class="section level3">
<h3><span class="header-section-number">7.8.2</span> Manual refinement</h3>
<p>Now, you’re good to download your contig database, merged profile directory, and CheckM table onto your local machine for further manual refinement since you’ll need the power of an internet browser to visually do the refinement. Make sure anvi’o is installed on that local machine. Also, keep an extra copy of these in case you make a mistake during manual refinement.</p>
<p>Manual refinement on anvi’o is described in great detail <a href="http://merenlab.org/2017/05/11/anvi-refine-by-veronika/">here</a></p>
<iframe src="http://merenlab.org/2017/05/11/anvi-refine-by-veronika/?showcase=0" width="672" height="600px">
</iframe>
</div>
<div id="iterative-assessment-and-refinement-1" class="section level3">
<h3><span class="header-section-number">7.8.3</span> Iterative assessment and refinement</h3>
<p>After manual refinement of the bins using anvi’o, iteratively run quality assessment and manual refinement of high contamination bins until you have a list of bins which are more than 90 % complete and less than 10 % contaminated.</p>
</div>
<div id="store-bins-on-the-server" class="section level3">
<h3><span class="header-section-number">7.8.4</span> Store bins on the server</h3>
<p>Once your done, repeat the following:</p>
<p><code>anvi-summarize -p SI072_MERGED_Profile/PROFILE.db -c SI072_Dedupe_contigs.db -o SI072_SUMMARY_Ref_X -C dastool</code></p>
<p>Make a directory to put the fasta files to put your bins into:</p>
<p><code>mkdir SI072_Bins_Ref_X</code></p>
<p>Copy the fasta files into your new directory:</p>
<p><code>cp SI072_SUMMARY_MERGE_Ref_X /bin_by_bin/*/*.fa SI072_Bins_Ref_X</code></p>
<p>Copy the directory SI072_Bins_Ref_X back to your server with:</p>
<p><code>scp -r SI072_Bins_Ref_X username@server:/path</code></p>
</div>
</div>
<div id="assigning-gtdb-taxonomy-to-your-bins" class="section level2">
<h2><span class="header-section-number">7.9</span> Assigning GTDB taxonomy to your bins</h2>
<p>Once you’ve got the final version of your bins on the server, you’re well positioned to assign taxonomy to your bins:</p>
</div>
<div id="make-sure-to-echo-the-gtdb-tk-data-pathecho" class="section level2">
<h2><span class="header-section-number">7.10</span> Make sure to echo the GTDB-Tk data pathecho</h2>
<p><code>"export GTDBTK_DATA_PATH= /mnt/nfs/sharknado/LimsData/Hallam_Databases/formatted/GTDB-TK/release95/" &gt; /miniconda3/envs/gtdbtk-1.3.0/etc/conda/activate.d/gtdbtk.sh</code></p>
<p><code>gtdbtk classify_wf --genome_dir ~/SI072_Data/SI072_Dedupe/SI072_Bins_Ref_5/ --out_dir ~/SI072_Data/SI072_Dedupe/SI072_Bins_Ref_5_GTDB_r95/ -x .fa --cpus 4</code></p>
</div>
<div id="working-with-treesapp" class="section level2">
<h2><span class="header-section-number">7.11</span> Working with TreeSAPP</h2>
<p>Now that we have medium and high quality bins and their taxonomic identity, we move on to work with TreeSAPP for automated reconstruction of the nitrogen cycle.</p>
</div>
<div id="treesapp-script" class="section level2">
<h2><span class="header-section-number">7.12</span> TreeSAPP script</h2>
<p>Please use this script to work with TreeSAPP. The file paths are provided in the <code>.csv</code> file <a href="treesapp_paths.csv"><code>treesapp_paths.csv</code></a>.</p>
<p>Run this script from the same folder as your path file.</p>
<pre><code>!/bin/bash


#activate conda treesapp environment prior to running w/

conda activate treesapp_cenv


#set file reading in for path info

paths_file=&quot;treesapp_paths.csv&quot;

#make variable for ref pkg directory path

refpkg_path=&quot;/projects/micb405/resources/metagenomics_data/MICB405_Project_Files/12_MICB405_refpkgs&quot;

#make main directory for TreeSAPP outputs
#corresponds to .csv main output directory
#TreeSAPP will make individual iteration output subdirectories
#w/in this main directory based on paths_file

mkdir TreeSAPP_Outputs

#change permissions so everyone has rwx privilege

chmod -R 777 TreeSAPP_Outputs

#loop through each line of paths_file
#each line represents an interation of TreeSAPP
#use fields in each line to run an iteration of TreeSAPP
#$f1 is the assembly file (fasta). Please assign the variable f1 the path to the assembly fasta file
#$f2 is the reads file (fastq). Please assign the variable f2 the path to the fastq file
#$f3 is the output directory. Please assign the variable f3 the path to the output directory

while IFS=, read -r f1 f2 f3
do

#debugging echoes
#  echo &quot;assembly file:${f1}&quot;
#  echo &quot;reads file: ${f2}&quot;
#  echo &quot;output directory: ${f3}&quot;

treesapp assign -i ${f1} -n 4 -m dna -r ${f2} -p pe -o ${f3} --refpkg_dir $refpkg_path --rpkm --trim_align --verbose --delete

#change permissions on output subdirectories to rwx for everyone

chmod -R 777 ${f3}
done &lt; $paths_file

##remember to deactivate conda treesapp environment after running

conda deactivate</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="processing-mags.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
},
"link": "GitHub repo link"
});
});
</script>

</body>

</html>
